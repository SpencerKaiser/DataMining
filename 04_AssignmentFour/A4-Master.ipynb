{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment Four - CRISP-DM Capstone: Association Rule Mining, Clustering, or Collaborative Filtering\n",
    "===\n",
    "##Hector Curi - Spencer Kaiser\n",
    "\n",
    "---\n",
    "Instructions\n",
    "---\n",
    "In the final assignment for this course, you will be using one of three different analysis methods:\n",
    "\n",
    "* Option A: Use transaction data for mining associations rules\n",
    "* Option B: Use clustering on an unlabeled dataset to provide insight or features\n",
    "* Option C: Use collaborative filtering to build a custom recommendation system\n",
    "\n",
    "Your choice of dataset will largely determine the task that you are trying to achieve. Though the dataset does not need to change from your previous tasks. For example, you might choose to use clustering on your data as a preprocessing step that extracts different features. Then you can use those features to build a classifier and analyze its performance in terms of accuracy (precision, recall) and speed. Alternatively, you might choose a completely different dataset and perform rule mining or build a recommendation system.\n",
    "\n",
    "---\n",
    "Dataset Selection and Toolkits\n",
    "---\n",
    "As before, you need to choose a dataset that is not small. It might be massive in terms of the number of attributes (or transactions), classes (or items, users, etc.) or whatever is appropriate for the task you are performing. Note that scikit-learn can be used for clustering analysis, but not for Association Rule Mining (you should use R) or collaborative filtering (you should use graphlab-create from Dato). Both can be run using iPython notebooks as perfomed in class.\n",
    "\n",
    "Write a report covering in detail all the steps of the project. The results need to be reproducible using only this report. Describe all assumptions you make and include all code you use in the iPython notebook or as supplemental functions. Follow the CRISP-DM framework in your analysis (you are performing all of the CRISP-DM outline). This report is worth 20% of the final grade.\n",
    "\n",
    "---\n",
    "### Choice of Task\n",
    "We are going to use the MovieLens movie ratings dataset to complete **Option C**. We plan on utilizing over 100,000 user ratings of 8,570 movies to create a user-item collaborative filtering recommendation system.\n",
    "\n",
    "---\n",
    "### Initial Code\n",
    "Our first task was to create a usable dataset from the individual files created by MovieLens. We accomplished this by using the pandas `merge` function, then we wrote the result to a new file called `data.csv`. Each instance in this file now contains the id of both the user and the movie, the movie title, its rating, genres, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Start server at: ipc:///tmp/graphlab_server-566 - Server binary: /Library/Python/2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1431391598.log\n",
      "[INFO] GraphLab Server Version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "#import all packages used in this assignment\n",
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from numpy import random as rd\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "# read in the separate csv files (ratings and movies) and combine them into one for easier use\n",
    "df1 = pd.read_csv('data/ratings.csv')\n",
    "df2 = pd.read_csv('data/movies.csv')\n",
    "merged = df1.merge(df2, on=\"movieId\", how=\"outer\").fillna(\"\")\n",
    "merged.to_csv(\"data/data.csv\", index=False)\n",
    "\n",
    "# read in final merged file\n",
    "data = gl.SFrame.read_csv(\"data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Start server at: ipc:///tmp/graphlab_server-537 - Server binary: /Library/Python/2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1431391355.log\n",
      "[INFO] GraphLab Server Version: 1.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Finished parsing file /Users/hcuri/Dropbox/SMU/Classes/ CSE 5331 - Data Mining/Assignments/DataMining/04_AssignmentFour/data/data.csv\n",
      "PROGRESS: Parsing completed. Parsed 100 lines in 0.140788 secs.\n",
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[float,float,float,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Finished parsing file /Users/hcuri/Dropbox/SMU/Classes/ CSE 5331 - Data Mining/Assignments/DataMining/04_AssignmentFour/data/data.csv\n",
      "PROGRESS: Parsing completed. Parsed 100041 lines in 0.123408 secs.\n"
     ]
    }
   ],
   "source": [
    "data = gl.SFrame.read_csv(\"data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SFrame.head of Columns:\n",
       "\tuserId\tfloat\n",
       "\tmovieId\tfloat\n",
       "\trating\tfloat\n",
       "\ttimestamp\tfloat\n",
       "\ttitle\tstr\n",
       "\tgenres\tstr\n",
       "\n",
       "Rows: 100041\n",
       "\n",
       "Data:\n",
       "+--------+---------+--------+--------------+-------------+-----------------------+\n",
       "| userId | movieId | rating |  timestamp   |    title    |         genres        |\n",
       "+--------+---------+--------+--------------+-------------+-----------------------+\n",
       "|  1.0   |   6.0   |  2.0   | 980730861.0  | Heat (1995) | Action|Crime|Thriller |\n",
       "|  8.0   |   6.0   |  5.0   | 964736358.0  | Heat (1995) | Action|Crime|Thriller |\n",
       "|  9.0   |   6.0   |  3.0   | 844674216.0  | Heat (1995) | Action|Crime|Thriller |\n",
       "|  16.0  |   6.0   |  2.0   | 855198917.0  | Heat (1995) | Action|Crime|Thriller |\n",
       "|  19.0  |   6.0   |  4.0   | 1154985045.0 | Heat (1995) | Action|Crime|Thriller |\n",
       "|  21.0  |   6.0   |  4.0   | 865106909.0  | Heat (1995) | Action|Crime|Thriller |\n",
       "|  31.0  |   6.0   |  5.0   | 1186249974.0 | Heat (1995) | Action|Crime|Thriller |\n",
       "|  60.0  |   6.0   |  5.0   | 1264525122.0 | Heat (1995) | Action|Crime|Thriller |\n",
       "|  87.0  |   6.0   |  5.0   | 848503814.0  | Heat (1995) | Action|Crime|Thriller |\n",
       "|  96.0  |   6.0   |  5.0   | 882593416.0  | Heat (1995) | Action|Crime|Thriller |\n",
       "|  ...   |   ...   |  ...   |     ...      |     ...     |          ...          |\n",
       "+--------+---------+--------+--------------+-------------+-----------------------+\n",
       "[100041 rows x 6 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Understanding\n",
    "---\n",
    "\n",
    "---\n",
    "### 1. Business Purpose & Implications of Analysis (10 points)\n",
    "**Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effectiveness of a good algorithm and why does this method make sense for this specific dataset and the stakeholders needs?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary purpose of this dataset, and it’s creation, is for research purposes. Other similar datasets have been made, however, these datasets were primarily made available for competition purposes in order to improve a business’s recommendation model.\n",
    "\n",
    "Regarding how an analysis of this data set may be used in the real-world, one of the most beneficial uses of the resulting system would be for movie streaming services like Netflix. Netflix is constantly adding new movies to their offering that they believe will be in high demand. At the same time, they are constantly removing under-performing titles. They do this in order to maximize the revenue generated from each title after paying licensing fees, to make sure their offering remains current and relevant, and they also do this to ensure that users of the service are happy with what they are paying for. \n",
    "\n",
    "Our recommendation system could be used to help Netflix fine-tune their offering to best meet the needs of their current subscribers. It could be used to help identify new movies that may be popular and it could also be used to help determine which movies are the least popular.\n",
    "\n",
    "We will use cross validation to measure the effectiveness of our algorithm. Using precision and recall, we can estimate how many of our recommender system predictions are correct and how many don't match our testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Understanding\n",
    "---\n",
    "\n",
    "---\n",
    "### 1. WRITE TITLE (10 points)\n",
    "**Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[INSERT ATTRIBUTE ANALYSIS HERE]**\n",
    "\n",
    "Data collection for this dataset began in April of 1996. Since then, the data set has gone through multiple iterations and the result is a high-quality, well-polished dataset. The dataset does not contain missing values in the traditional sense, however, according to the creators of the dataset “Only movies with at least one rating or tag are included in the dataset”, so some instances have missing values for the ratings field. Because the the quantity of these types of instances is low and because we are primarily focusing on rating, we will be removing these instances from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_raw.rating.min()\n",
    "df_raw.rating.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, there are no apparent outliers in the set. The scale users rank movies on allows values from 0.5 to 5.0 with increments of 0.5. After running a `min` and a `max` of the dataset, we can see there are no incorrect values (outliers in this case) for the ratings field. Lastly, the dataset contains no duplicate instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. WRITE TITLE (10 points)\n",
    "**Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and Evaluation (50 points)\n",
    "---\n",
    "\n",
    "Different tasks will require different evaluation methods. Be as thorough as possible when analyzing the data you have chosen and use visualizations of the results to explain the performance and expected outcomes whenever possible. Guide the reader through your analysis with plenty of discussion of the results.\n",
    "\n",
    "---\n",
    "### 1. WRITE TITLE\n",
    "**Create user-item matrices or item-item matrices using collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. WRITE TITLE\n",
    "**Determine performance of the recommendations using different performance measures.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. WRITE TITLE\n",
    "**Use tables/visualization to discuss the found results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. WRITE TITLE\n",
    "**Describe your results. What findings are the most compelling and why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment (10 points)\n",
    "---\n",
    "Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you acheive your goals? If not, can you reign in the utility of your modeling?\n",
    "\n",
    "---\n",
    "### 1. WRITE TITLE\n",
    "**How useful is your model for interested parties (i.e., the companies or organizations that might want to use it)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. WRITE TITLE\n",
    "**How would your deploy your model for interested parties?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. WRITE TITLE\n",
    "**What other data should be collected?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. WRITE TITLE\n",
    "**How often would the model need to be updated, etc.?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exceptional Work (10 points)\n",
    "---\n",
    "\n",
    "---\n",
    "**You have free reign to provide additional analyses or combine analyses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                                 .''.\n",
    "       .''.             *''*    :_\\/_:     .\n",
    "      :_\\/_:   .    .:.*_\\/_*   : /\\ :  .'.:.'.\n",
    "  .''.: /\\ : _\\(/_  ':'* /\\ *  : '..'.  -=:o:=-\n",
    " :_\\/_:'.:::. /)\\*''*  .|.* '.\\'/.'_\\(/_'.':'.'\n",
    " : /\\ : :::::  '*_\\/_* | |  -= o =- /)\\    '  *\n",
    "  '..'  ':::'   * /\\ * |'|  .'/.\\'.  '._____\n",
    "      *        __*..* |  |     :      |.   |' .---\"|\n",
    "       _*   .-'   '-. |  |     .--'|  ||   | _|    |\n",
    "    .-'|  _.|  |    ||   '-__  |   |  |    ||      |\n",
    "    |' | |.    |    ||       | |   |  |    ||      |\n",
    " ___|  '-'     '    \"\"       '-'   '-.'    '`      |____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
